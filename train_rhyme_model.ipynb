{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JAT0G4jPKmb",
    "outputId": "9c7919c5-7278-4dcc-f885-69f6cd35a494"
   },
   "outputs": [],
   "source": [
    "#! pip3 install tqdm\n",
    "#! pip3 install tensorflow\n",
    "#! pip install numpy\n",
    "#! pip3 install pandas\n",
    "#! pip3 install sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Subtract\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TerminateOnNaN, CSVLogger\n",
    "tqdm.pandas()\n",
    "\n",
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5tJC-r1CEWv"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2YPa_dRcvAhw"
   },
   "outputs": [],
   "source": [
    "def tokenize_inputs(phrase_a, phrase_b, tokenizer):\n",
    "\n",
    "    tokenized_phrases = tokenizer.texts_to_sequences([phrase_a, phrase_b])\n",
    "\n",
    "    # now loop through inputs and pad or reduce size if required\n",
    "    tokenized_phrases_for_output = []\n",
    "    for phrase in tokenized_phrases:\n",
    "        if len(phrase) < MAX_LEN:\n",
    "            length_to_pad = MAX_LEN - len(phrase)\n",
    "            phrase_for_output = ([0] * length_to_pad) + phrase\n",
    "        elif len(phrase) > MAX_LEN:\n",
    "            phrase_for_output = phrase[-MAX_LEN:]\n",
    "        else:\n",
    "            phrase_for_output = phrase\n",
    "        tokenized_phrases_for_output.append(phrase_for_output)\n",
    "\n",
    "    return tf.constant(tokenized_phrases_for_output, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of model**\n",
    "\n",
    "This is where we create the keras model. You will notice that I define a `common_lstm` layer. This is the siamese portion of the model which will have the same weights for both input (tokenized words). From here the output veotrs of these layers are subtracted before the resulting vector is passed through a series of dense layers which produces the fial classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qpSfDtYvDXJJ"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "    word_a_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_a_input_tokens'\n",
    "      )\n",
    "    word_b_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_b_input_tokens'\n",
    "      )\n",
    "\n",
    "    common_lstm = LSTM(64, return_sequences=False, activation=\"relu\", name=\"common_lstm_layer\")\n",
    "\n",
    "    word_a_lstm_output = common_lstm(word_a_input_tokens)\n",
    "    word_b_lstm_output = common_lstm(word_b_input_tokens)\n",
    "\n",
    "    #concatenate_lstm_outputs\n",
    "    concat_layer = Subtract(name=\"concatenate_lastm_outputs\")(\n",
    "      [word_a_lstm_output, word_b_lstm_output]\n",
    "      )\n",
    "    \n",
    "    # dense layers before final classification\n",
    "    dense_layers = Dense(64, activation=\"relu\", name=\"first_dense_layer\")(concat_layer)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(32, activation=\"relu\", name=\"second_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(8, activation=\"relu\", name=\"third_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    classification_layer = Dense(1, activation=\"sigmoid\", name=\"classification_layer\")(dense_layers)\n",
    "    \n",
    "    model = Model(\n",
    "      inputs=[word_a_input_tokens, word_b_input_tokens], \n",
    "      outputs = classification_layer\n",
    "      )\n",
    "\n",
    "    model.compile(\n",
    "      loss=\"binary_crossentropy\",\n",
    "      metrics=[\"accuracy\"],\n",
    "      optimizer=\"Adam\"\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data \n",
    "\n",
    "Load the data from the rhyme and non-rhyme files we created previously. Note due to hardware limitations I only focused on a subset of 1,000,000 word pairs but you can use more or less than this depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Y9gWLLSQCYMt",
    "outputId": "693979c2-f176-49f5-8482-f39ff922b6b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhyme_id</th>\n",
       "      <th>rhyme_group_id</th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190131</th>\n",
       "      <td>246172</td>\n",
       "      <td>111</td>\n",
       "      <td>es his</td>\n",
       "      <td>esse is</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32885</th>\n",
       "      <td>32886</td>\n",
       "      <td>9</td>\n",
       "      <td>chaebol</td>\n",
       "      <td>grable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206073</th>\n",
       "      <td>273379</td>\n",
       "      <td>125</td>\n",
       "      <td>braithwaite of</td>\n",
       "      <td>distillate of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356273</th>\n",
       "      <td>480878</td>\n",
       "      <td>207</td>\n",
       "      <td>spry</td>\n",
       "      <td>magpie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337155</th>\n",
       "      <td>461757</td>\n",
       "      <td>202</td>\n",
       "      <td>geez</td>\n",
       "      <td>sees</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rhyme_id  rhyme_group_id          word_a         word_b  rhyme\n",
       "190131    246172             111          es his        esse is      1\n",
       "32885      32886               9         chaebol         grable      1\n",
       "206073    273379             125  braithwaite of  distillate of      1\n",
       "356273    480878             207            spry         magpie      1\n",
       "337155    461757             202            geez           sees      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme_df = pd.read_csv('data/rhymes/rhyme_df.csv')\n",
    "rhyme_df = rhyme_df.dropna(subset=['word_a', 'word_b', 'rhyme'])\n",
    "non_rhyme_df = pd.read_csv('data/rhymes/non_rhyme_df.csv')\n",
    "non_rhyme_df = non_rhyme_df.dropna(subset=['word_a', 'word_b', 'rhyme'])\n",
    "\n",
    "df = pd.concat([\n",
    "        rhyme_df.sample(400_000, random_state=123), \n",
    "        non_rhyme_df.sample(400_000, random_state=123)\n",
    "    ])\n",
    "del rhyme_df, non_rhyme_df\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd3XN7sGdNSo"
   },
   "source": [
    "# Tokenize inputs\n",
    "\n",
    "Create and fit a tokenizer on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "182dea908f4543268f1eb00fdf208169",
      "a2164716defd42248afadcfa2a464f19",
      "2e581bb339fc41e984b75e5f473043bb",
      "762776797fd247cdaff619f3fecfe7c7",
      "5ddb350805d3455c9fbc4826761b2f25",
      "c994c61b206f412ab6fe2c3f304bc096",
      "642d732105924b85b550012f72b19ca4",
      "8a2dd43b441f4d918fa0101c26b2bafc"
     ]
    },
    "id": "dsNL_CXGDIXa",
    "outputId": "5cf492bb-ba17-4a71-efd2-272987d0635a"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts(df['word_a'] + df['word_b'])\n",
    "\n",
    "df['word_tokens'] = df.apply(lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcDoh8M8kgp7"
   },
   "source": [
    "# Split data into train (60%) test (30%) and validation (10%) sets\n",
    "\n",
    "Use stratified random sampling to create train, test and va;idation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZFmqgCVbhioA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df['word_tokens']), list(df['rhyme']), stratify=df['rhyme'], \n",
    "    test_size=0.4, random_state=123\n",
    "    )\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test, y_test, stratify=y_test, test_size=0.25, random_state=123\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jdaS_M4Mu85D"
   },
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxXbS45koKHL"
   },
   "source": [
    "# Train model\n",
    "\n",
    "Call our model function and fit it on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92qfyi2EoJy-",
    "outputId": "f42f24ae-2556-46f3-d8e9-7b01da87ad73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 164s 43ms/step - loss: 0.4662 - accuracy: 0.8006 - val_loss: 0.3033 - val_accuracy: 0.8729\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 181s 48ms/step - loss: 0.3586 - accuracy: 0.8581 - val_loss: 0.2489 - val_accuracy: 0.9097\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 173s 46ms/step - loss: 0.3225 - accuracy: 0.8757 - val_loss: 0.2138 - val_accuracy: 0.9248\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 174s 46ms/step - loss: 0.2979 - accuracy: 0.8868 - val_loss: 0.2082 - val_accuracy: 0.9198\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.2811 - accuracy: 0.8942 - val_loss: 0.1881 - val_accuracy: 0.9333\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 176s 47ms/step - loss: 0.2723 - accuracy: 0.8988 - val_loss: 0.1750 - val_accuracy: 0.9379\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 177s 47ms/step - loss: 0.2592 - accuracy: 0.9034 - val_loss: 0.1701 - val_accuracy: 0.9386\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 180s 48ms/step - loss: 0.2465 - accuracy: 0.9090 - val_loss: 0.1626 - val_accuracy: 0.9415\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.2399 - accuracy: 0.9119 - val_loss: 0.1563 - val_accuracy: 0.9441\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 166s 44ms/step - loss: 0.2351 - accuracy: 0.9138 - val_loss: 0.1535 - val_accuracy: 0.9457\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.2305 - accuracy: 0.9157 - val_loss: 0.1532 - val_accuracy: 0.9442\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 152s 40ms/step - loss: 0.2277 - accuracy: 0.9160 - val_loss: 0.1491 - val_accuracy: 0.9477\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 153s 41ms/step - loss: 0.2224 - accuracy: 0.9185 - val_loss: 0.1574 - val_accuracy: 0.9410\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 144s 38ms/step - loss: 0.2198 - accuracy: 0.9197 - val_loss: 0.1385 - val_accuracy: 0.9507\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.2159 - accuracy: 0.9209 - val_loss: 0.1376 - val_accuracy: 0.9517\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.2120 - accuracy: 0.9220 - val_loss: 0.1358 - val_accuracy: 0.9510\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.2103 - accuracy: 0.9224 - val_loss: 0.1395 - val_accuracy: 0.9499\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.2053 - accuracy: 0.9245 - val_loss: 0.1314 - val_accuracy: 0.9524\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.2030 - accuracy: 0.9253 - val_loss: 0.1394 - val_accuracy: 0.9528\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.2001 - accuracy: 0.9266 - val_loss: 0.1222 - val_accuracy: 0.9584\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 143s 38ms/step - loss: 0.1985 - accuracy: 0.9272 - val_loss: 0.1338 - val_accuracy: 0.9553\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1967 - accuracy: 0.9280 - val_loss: 0.1212 - val_accuracy: 0.9583\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 153s 41ms/step - loss: 0.1943 - accuracy: 0.9286 - val_loss: 0.1268 - val_accuracy: 0.9573\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1913 - accuracy: 0.9300 - val_loss: 0.1233 - val_accuracy: 0.9572\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1897 - accuracy: 0.9309 - val_loss: 0.1172 - val_accuracy: 0.9605\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1864 - accuracy: 0.9318 - val_loss: 0.1189 - val_accuracy: 0.9599\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 152s 41ms/step - loss: 0.1863 - accuracy: 0.9320 - val_loss: 0.1160 - val_accuracy: 0.9610\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1837 - accuracy: 0.9334 - val_loss: 0.1154 - val_accuracy: 0.9621\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1832 - accuracy: 0.9338 - val_loss: 0.1138 - val_accuracy: 0.9617\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1819 - accuracy: 0.9339 - val_loss: 0.1095 - val_accuracy: 0.9636\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1800 - accuracy: 0.9347 - val_loss: 0.1101 - val_accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1792 - accuracy: 0.9353 - val_loss: 0.1114 - val_accuracy: 0.9647\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 152s 40ms/step - loss: 0.1765 - accuracy: 0.9366 - val_loss: 0.1111 - val_accuracy: 0.9642\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1752 - accuracy: 0.9370 - val_loss: 0.1122 - val_accuracy: 0.9623\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.1747 - accuracy: 0.9373 - val_loss: 0.1051 - val_accuracy: 0.9662\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1733 - accuracy: 0.9379 - val_loss: 0.1144 - val_accuracy: 0.9637\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1709 - accuracy: 0.9387 - val_loss: 0.1027 - val_accuracy: 0.9664\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1693 - accuracy: 0.9394 - val_loss: 0.1006 - val_accuracy: 0.9679\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 153s 41ms/step - loss: 0.1689 - accuracy: 0.9399 - val_loss: 0.1006 - val_accuracy: 0.9678\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1686 - accuracy: 0.9399 - val_loss: 0.1013 - val_accuracy: 0.9680\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1658 - accuracy: 0.9409 - val_loss: 0.1114 - val_accuracy: 0.9626\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1661 - accuracy: 0.9409 - val_loss: 0.0983 - val_accuracy: 0.9680\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1645 - accuracy: 0.9415 - val_loss: 0.0984 - val_accuracy: 0.9685\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.1634 - accuracy: 0.9422 - val_loss: 0.0966 - val_accuracy: 0.9695\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1626 - accuracy: 0.9427 - val_loss: 0.1009 - val_accuracy: 0.9677\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1641 - accuracy: 0.9421 - val_loss: 0.1027 - val_accuracy: 0.9662\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1602 - accuracy: 0.9440 - val_loss: 0.0956 - val_accuracy: 0.9700\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1581 - accuracy: 0.9444 - val_loss: 0.0953 - val_accuracy: 0.9695\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1591 - accuracy: 0.9437 - val_loss: 0.1044 - val_accuracy: 0.9656\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1582 - accuracy: 0.9440 - val_loss: 0.1019 - val_accuracy: 0.9674\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 152s 41ms/step - loss: 0.1587 - accuracy: 0.9443 - val_loss: 0.1153 - val_accuracy: 0.9632\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1581 - accuracy: 0.9444 - val_loss: 0.0942 - val_accuracy: 0.9701\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1553 - accuracy: 0.9461 - val_loss: 0.0906 - val_accuracy: 0.9723\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1554 - accuracy: 0.9455 - val_loss: 0.0891 - val_accuracy: 0.9725\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1561 - accuracy: 0.9456 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.1541 - accuracy: 0.9462 - val_loss: 0.0904 - val_accuracy: 0.9722\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1535 - accuracy: 0.9461 - val_loss: 0.0898 - val_accuracy: 0.9724\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1526 - accuracy: 0.9468 - val_loss: 0.0907 - val_accuracy: 0.9719\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.1521 - accuracy: 0.9471 - val_loss: 0.0952 - val_accuracy: 0.9708\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1513 - accuracy: 0.9473 - val_loss: 0.0877 - val_accuracy: 0.9734\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.1514 - accuracy: 0.9474 - val_loss: 0.0996 - val_accuracy: 0.9685\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1514 - accuracy: 0.9473 - val_loss: 0.0847 - val_accuracy: 0.9736\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1501 - accuracy: 0.9476 - val_loss: 0.1094 - val_accuracy: 0.9635\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1496 - accuracy: 0.9482 - val_loss: 0.0834 - val_accuracy: 0.9746\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1487 - accuracy: 0.9484 - val_loss: 0.0980 - val_accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1481 - accuracy: 0.9483 - val_loss: 0.0913 - val_accuracy: 0.9718\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1478 - accuracy: 0.9485 - val_loss: 0.0993 - val_accuracy: 0.9687\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1472 - accuracy: 0.9494 - val_loss: 0.0887 - val_accuracy: 0.9729\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1460 - accuracy: 0.9494 - val_loss: 0.0890 - val_accuracy: 0.9720\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1455 - accuracy: 0.9493 - val_loss: 0.0859 - val_accuracy: 0.9737\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1444 - accuracy: 0.9500 - val_loss: 0.0874 - val_accuracy: 0.9730\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 148s 40ms/step - loss: 0.1450 - accuracy: 0.9501 - val_loss: 0.0809 - val_accuracy: 0.9757\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 153s 41ms/step - loss: 0.1445 - accuracy: 0.9499 - val_loss: 0.0805 - val_accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1435 - accuracy: 0.9504 - val_loss: 0.0822 - val_accuracy: 0.9757\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1444 - accuracy: 0.9502 - val_loss: 0.0908 - val_accuracy: 0.9729\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1421 - accuracy: 0.9507 - val_loss: 0.0817 - val_accuracy: 0.9756\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1428 - accuracy: 0.9507 - val_loss: 0.0874 - val_accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.1419 - accuracy: 0.9512 - val_loss: 0.1104 - val_accuracy: 0.9646\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1418 - accuracy: 0.9515 - val_loss: 0.0848 - val_accuracy: 0.9749\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1405 - accuracy: 0.9517 - val_loss: 0.0785 - val_accuracy: 0.9767\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 0.0910 - val_accuracy: 0.9726\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1400 - accuracy: 0.9524 - val_loss: 0.0809 - val_accuracy: 0.9760\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1382 - accuracy: 0.9527 - val_loss: 0.0828 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.1411 - accuracy: 0.9514 - val_loss: 0.0829 - val_accuracy: 0.9746\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.1380 - accuracy: 0.9526 - val_loss: 0.0788 - val_accuracy: 0.9762\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1392 - accuracy: 0.9526 - val_loss: 0.0821 - val_accuracy: 0.9754\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1405 - accuracy: 0.9519 - val_loss: 0.0796 - val_accuracy: 0.9761\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 149s 40ms/step - loss: 0.1375 - accuracy: 0.9529 - val_loss: 0.0790 - val_accuracy: 0.9766\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 144s 38ms/step - loss: 0.1389 - accuracy: 0.9526 - val_loss: 0.0826 - val_accuracy: 0.9754\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 155s 41ms/step - loss: 0.1364 - accuracy: 0.9533 - val_loss: 0.0809 - val_accuracy: 0.9763\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1369 - accuracy: 0.9537 - val_loss: 0.0759 - val_accuracy: 0.9776\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.1380 - accuracy: 0.9529 - val_loss: 0.0813 - val_accuracy: 0.9759\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1355 - accuracy: 0.9538 - val_loss: 0.0784 - val_accuracy: 0.9764\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 146s 39ms/step - loss: 0.1353 - accuracy: 0.9540 - val_loss: 0.0817 - val_accuracy: 0.9750\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1370 - accuracy: 0.9534 - val_loss: 0.0763 - val_accuracy: 0.9776\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 148s 39ms/step - loss: 0.1355 - accuracy: 0.9541 - val_loss: 0.0784 - val_accuracy: 0.9767\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1353 - accuracy: 0.9542 - val_loss: 0.0753 - val_accuracy: 0.9776\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 145s 39ms/step - loss: 0.1357 - accuracy: 0.9540 - val_loss: 0.0784 - val_accuracy: 0.9765\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 152s 41ms/step - loss: 0.1343 - accuracy: 0.9541 - val_loss: 0.0783 - val_accuracy: 0.9770\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 147s 39ms/step - loss: 0.1342 - accuracy: 0.9544 - val_loss: 0.0739 - val_accuracy: 0.9783\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\"models/rhyme_model.hdf5\",monitor=\"val_loss\")\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]],\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=[model_checkpoint, terminate_on_nan, csv_logger],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gybqTytz4BXB"
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DFFz7qB1hr6S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 53s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(\"models/rhyme_model.hdf5\")\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2wjPSHp2SHe",
    "outputId": "222d2460-7be6-4f13-daac-6218e3724caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    120000\n",
      "           1       0.97      0.99      0.98    120000\n",
      "\n",
      "    accuracy                           0.98    240000\n",
      "   macro avg       0.98      0.98      0.98    240000\n",
      "weighted avg       0.98      0.98      0.98    240000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model on some examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Daj1qHucLWJ5",
    "outputId": "7f15c838-501b-417a-978b-28c7c919ce86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric 1: Cornish hens switchin' positions\n",
      "Lyric 2: auditionin' mortitions\n",
      "Rhyme(0.9860000014305115)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Lived happily ever after\n",
      "Lyric 2: but that's another chapter\n",
      "Rhyme(0.9860000014305115)\n",
      "---------------\n",
      "\n",
      "Lyric 1: I keep some E&J, sittin' bent up in the stairway\n",
      "Lyric 2: Y'all know my steelo, with or without the airplay\n",
      "Rhyme(0.9652000069618225)\n",
      "---------------\n",
      "\n",
      "Lyric 1: I guess every superhero need his theme music\n",
      "Lyric 2: No one man should have all that power\n",
      "Non-rhyme(0.0)\n",
      "---------------\n",
      "\n",
      "Lyric 1: In the city of L.A\n",
      "Lyric 2: In the city of good ol' Watts\n",
      "Non-rhyme(0.0)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "   [\"soap\", \"hope\"], # \n",
    "   [\"cat\", \"hat\"], # \n",
    "   [\"sliver\", \"cleaver\"],# Nas rhyme\n",
    "   [\"inspire\", \"desire\"], # Kanye non-rhyme\n",
    "   [\"tomato\", \"salad\"], # Tupac non-rhyme\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Lyric 1: {samples[i][0]}\")\n",
    "    print(f\"Lyric 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_rhyme_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b4154a5e50f28955d572e0ac127fc80516f324e00a012c5e576aefb5da48c4f4"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "182dea908f4543268f1eb00fdf208169": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e581bb339fc41e984b75e5f473043bb",
       "IPY_MODEL_762776797fd247cdaff619f3fecfe7c7"
      ],
      "layout": "IPY_MODEL_a2164716defd42248afadcfa2a464f19"
     }
    },
    "2e581bb339fc41e984b75e5f473043bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c994c61b206f412ab6fe2c3f304bc096",
      "max": 1000000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ddb350805d3455c9fbc4826761b2f25",
      "value": 1000000
     }
    },
    "5ddb350805d3455c9fbc4826761b2f25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "642d732105924b85b550012f72b19ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "762776797fd247cdaff619f3fecfe7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a2dd43b441f4d918fa0101c26b2bafc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_642d732105924b85b550012f72b19ca4",
      "value": " 1000000/1000000 [00:50&lt;00:00, 19636.03it/s]"
     }
    },
    "8a2dd43b441f4d918fa0101c26b2bafc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2164716defd42248afadcfa2a464f19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c994c61b206f412ab6fe2c3f304bc096": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
